{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f491f26-2e79-498e-8fb3-b815864cbc95",
   "metadata": {},
   "source": [
    "Parameters used in the code:\n",
    "\n",
    "N: Number of sites in the transverse field Ising model.\n",
    "\n",
    "This code can optimize 12 or higher sites because we are using pytorch with GPU support\n",
    "\n",
    "B: B-field value for the target Hamiltonian, which can be zero or non-zero.\n",
    "\n",
    "J_value: J coupling strength.\n",
    "\n",
    "J_matrix_alpha: Power-law decay constant.\n",
    "\n",
    "x: the best field used in modulated time evolution, the first half is $\\lambda (t)$ while the second half is $B(t)$\n",
    "\n",
    "number_of_layers: The number of steps in the modulated time evolution.\n",
    "\n",
    "\n",
    "There are two final output files,\n",
    "- f'QAOA_training_log_N={N}_B={B}_layers_{np.sum(p_list)}.txt'\n",
    "- f'QAOA_checkpoint_log_N={N}_B={B}_layers_{np.sum(p_list)}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b430f037-3e18-4743-9e26-db17fa62a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# initialize variables\n",
    "N = 12\n",
    "B = 0.1\n",
    "J_value = 1\n",
    "J_matrix_alpha =  1\n",
    "number_of_layers=10\n",
    "x =np.array([0.4072185919308115, 1.2954691806813516, 0.5805573609066998, 0.8454189546075643, 1.2243197218332320, 2.1572222947038711, 2.5905765854250022, 2.7409062412055198, 2.0081536293189819, 0.9755810490605400, 4.9955913368774452, 1.7717120168593767, 1.0871728400196139, 0.7185240323450447, 0.5732536483420920, 0.4951459317676031, 0.4388398363271400, 0.3901464618527199, 0.3117549554184353, 0.1945036761838408])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07cb000c-4018-47fb-9edd-9560d594fa91",
   "metadata": {
    "id": "07cb000c-4018-47fb-9edd-9560d594fa91",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from scipy.sparse.linalg import eigs\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.interpolate import Akima1DInterpolator\n",
    "from scipy.linalg import expm\n",
    "import time\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import scipy\n",
    "np.set_printoptions(precision=6)\n",
    "# initialize variables\n",
    "# Q is the dimension\n",
    "Q = pow(2, N)\n",
    "\n",
    "# decimal number to binary array function\n",
    "def D2B(num):\n",
    "    string = f'{num:1b}'\n",
    "    result = np.zeros(N - len(string), int)\n",
    "\n",
    "    for ele in string:\n",
    "        result = np.append(result, int(ele))\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_fidelity_torch(vector1, vector2):\n",
    "    overlap = torch.tensordot(vector1, vector2, dims=1)\n",
    "    overlap_conj = torch.conj(overlap)\n",
    "    fidelity = torch.real(overlap * overlap_conj)\n",
    "    return fidelity\n",
    "\n",
    "def get_energy_torch(matrix, vector):\n",
    "    conj_vector = torch.conj(vector)\n",
    "    energy = torch.real(torch.tensordot(conj_vector, torch.tensordot(matrix, vector, dims=1), dims=1)).to(torch.float64)\n",
    "    return energy\n",
    "    \n",
    "# decimal number to binary array function\n",
    "def D2B_with_digit(num,digit):\n",
    "    string = f'{num:1b}'\n",
    "    result = np.zeros(digit - len(string), int)\n",
    "\n",
    "    for ele in string:\n",
    "        result = np.append(result, int(ele))\n",
    "\n",
    "    return result\n",
    "\n",
    "# binary array to decimal function\n",
    "def B2D(array):\n",
    "    res = 0\n",
    "    for ele in array:\n",
    "        res = (res << 1) | ele\n",
    "    return res\n",
    "\n",
    "def spin_reflection(array):\n",
    "    new_array = np.zeros(len(array),dtype=int)\n",
    "    for i in range(len(array)):\n",
    "        if array[i] == 1:\n",
    "            new_array[i] = 0\n",
    "        else:\n",
    "            new_array[i] = 1\n",
    "    return new_array\n",
    "\n",
    "def spatial_reflection(array):\n",
    "    new_array = array[::-1]\n",
    "    return new_array\n",
    "\n",
    "# start my main function\n",
    "\n",
    "# initialize J matrix\n",
    "J_matrix = np.zeros((N, N), dtype='float64')\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if j >= (i + 1):\n",
    "            J_matrix[i][j] = J_value/pow(abs(i-j),J_matrix_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb008183-6972-46e7-91fa-97cd7797b695",
   "metadata": {
    "id": "bb008183-6972-46e7-91fa-97cd7797b695",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start to get what product states are having the same symmtries\n",
    "loop_state_list = np.linspace(0,Q-1,num=Q,dtype=int)\n",
    "\n",
    "couple_state_matrix = []\n",
    "sign_matrix = []\n",
    "# this is the final result for the states to consctruct basis \n",
    "\n",
    "for n in range(Q):  # n is an unused index\n",
    "    \n",
    "    # couple_num_list would be my result for each state we loop\n",
    "    \n",
    "    if len(loop_state_list)!=0: # loop for couple number for one state\n",
    "                \n",
    "        couple_num_list = [] # this is the list to store all the number that couple to the number we are looping\n",
    "        couple_num_list = np.array(couple_num_list, dtype=int)\n",
    "        state_num = loop_state_list[0]\n",
    "        couple_num_list = np.append(couple_num_list,state_num)\n",
    "        \n",
    "        for m in range(Q): # loop for spin and spatial for all states inside the couple number list\n",
    "            \n",
    "            if m==0:\n",
    "                \n",
    "                couple_num_list_old =couple_num_list\n",
    "                \n",
    "                for i in range(len(couple_num_list)):\n",
    "                    number = couple_num_list[i]\n",
    "                    array = D2B(number)\n",
    "\n",
    "                    # spin reflection \n",
    "                    spin_relfection_array = spin_reflection(array)\n",
    "                    spin_number = B2D(spin_relfection_array)\n",
    "                    couple_num_list =np.append(couple_num_list,spin_number)\n",
    "\n",
    "\n",
    "\n",
    "                    # # spatial reflection \n",
    "                    spatial_relfection_array = spatial_reflection(array)\n",
    "                    spatial_number = B2D(spatial_relfection_array)\n",
    "                    couple_num_list =np.append(couple_num_list,spatial_number)\n",
    "                    \n",
    "                    # remove the repeated element \n",
    "                    couple_num_list = np.unique(couple_num_list)\n",
    "            else:\n",
    "                \n",
    "                if len(couple_num_list_old) != len(couple_num_list):\n",
    "                    # update couple_num_list_old first \n",
    "                    couple_num_list_old =couple_num_list\n",
    "                    \n",
    "                    for i in range(len(couple_num_list)):\n",
    "                        number = couple_num_list[i]\n",
    "                        array = D2B(number)\n",
    "\n",
    "                        # spin reflection \n",
    "                        spin_relfection_array = spin_reflection(array)\n",
    "                        spin_number = B2D(spin_relfection_array)\n",
    "                        couple_num_list =np.append(couple_num_list,spin_number)\n",
    "                        \n",
    "                        \n",
    "                        # # spatial reflection \n",
    "                        spatial_relfection_array = spatial_reflection(array)\n",
    "                        spatial_number = B2D(spatial_relfection_array)\n",
    "                        couple_num_list = np.append(couple_num_list,spatial_number)\n",
    "                        \n",
    "                        # remove the repeated element \n",
    "                        couple_num_list = np.unique(couple_num_list)\n",
    "                        \n",
    "        # now we have final couple_num_list\n",
    "        couple_state_matrix.append(couple_num_list.tolist())\n",
    "        \n",
    "        # remove the ones already found \n",
    "        for j in range(len(couple_num_list)):\n",
    "            loop_state_list = np.delete(loop_state_list, np.where(loop_state_list ==couple_num_list[j] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa852452-dc21-45dd-8d22-9bdf391702d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# initialize H matrix\n",
    "couple_dimen = len(couple_state_matrix)\n",
    "\n",
    "HA_matrix = np.zeros((couple_dimen, couple_dimen), dtype='float64')\n",
    "HB_matrix = np.zeros((couple_dimen, couple_dimen), dtype='float64')\n",
    "\n",
    "# loop each basis to fill in the diagonal elements for HA matrix \n",
    "\n",
    "for i in range(couple_dimen):\n",
    "    \n",
    "    state_array = np.array( couple_state_matrix[i] )\n",
    "    \n",
    "    # loop each element inside the array \n",
    "    normalization = len(state_array)\n",
    "    \n",
    "    # energy total for all the product states inside one basis\n",
    "    \n",
    "    e_tot = 0\n",
    "    for j in range(len(state_array)):\n",
    "        \n",
    "        state = D2B(state_array[j])\n",
    "        \n",
    "        # loop over N sites to change the state vector to either 1 or -1\n",
    "        \n",
    "        for k in range(N):\n",
    "            # 1 is spin down , 0 is spin up\n",
    "            if state[k] == 1:\n",
    "                state[k] = -1\n",
    "            else:\n",
    "                state[k] = 1\n",
    "\n",
    "        # now get the energy, loop all the sites and then pairs\n",
    "        \n",
    "        for m in range(N):\n",
    "            for q in range(N):\n",
    "                e_temp = J_matrix[m][q] * state[m] * state[q]\n",
    "                e_tot = e_tot + e_temp\n",
    "\n",
    "    HA_matrix[i][i] = e_tot/normalization\n",
    "\n",
    "# generate vector form for each basis\n",
    "vector_form_basis_matrix = np.zeros((couple_dimen,Q))\n",
    "\n",
    "for i in range(couple_dimen):\n",
    "    \n",
    "    state_array = np.array( couple_state_matrix[i] )\n",
    "    normalization = np.sqrt(len(state_array))\n",
    "    \n",
    "    for j in state_array:\n",
    "        vector_form_basis_matrix[i][j] = 1\n",
    "        \n",
    "    # put back normalization factor\n",
    "    vector_form_basis_matrix[i] = vector_form_basis_matrix[i]/normalization\n",
    "    \n",
    "# loop each basis to fill in HB matrix \n",
    "\n",
    "for i in range(couple_dimen):\n",
    "\n",
    "    state_array = np.array( couple_state_matrix[i] )\n",
    "\n",
    "    # this is the actual normalization unlike before since it will couple to some other states\n",
    "    # so it can not be like just the square like we did before\n",
    "    normalization = np.sqrt(len(state_array))\n",
    "\n",
    "    # loop each product state to generate N other states, i.e. generaete the state after operator acting on it\n",
    "    result_num_list = []\n",
    "    result_num_list = np.array(result_num_list,dtype=int)\n",
    "    for k in range(len(state_array)):\n",
    "        \n",
    "        spin = D2B(state_array[k])\n",
    "\n",
    "        # start fliping the spins\n",
    "        for j in range(N):\n",
    "            if spin[j] == 1:\n",
    "                # if it's spin down, raise to spin up\n",
    "                spin[j] = 0\n",
    "                new_num = B2D(spin)\n",
    "                result_num_list = np.append(result_num_list,new_num)\n",
    "                # change it back for next operation\n",
    "                spin[j] = 1\n",
    "            else:\n",
    "                # if it's spin down, raise to spin up\n",
    "                spin[j] = 1\n",
    "                new_num = B2D(spin)\n",
    "                result_num_list = np.append(result_num_list,new_num)\n",
    "                # change it back for next operation\n",
    "                spin[j] = 0\n",
    "        \n",
    "     \n",
    "    # generate the vector form for the state after operrator acting on it\n",
    "    \n",
    "    vector_final_state = np.zeros(Q)\n",
    "    \n",
    "    for j in result_num_list:\n",
    "        vector_final_state[j] = vector_final_state[j] +1\n",
    "        \n",
    "    # put back normalization factor \n",
    "    vector_final_state = vector_final_state/normalization\n",
    "    \n",
    "    # calculate dot product to put into inside the matrix\n",
    "    for j in range(couple_dimen):\n",
    "        \n",
    "        dot_product = np.dot(vector_final_state,vector_form_basis_matrix[j])\n",
    "        HB_matrix[i][j] = dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a5a615f-4bba-4115-adac-33388d311370",
   "metadata": {
    "id": "4a5a615f-4bba-4115-adac-33388d311370",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the smallest eigenvalue and eigenvector\n",
    "smallest_eigenvalue, smallest_eigenvector = eigsh(HA_matrix + B * HB_matrix, k=1, which='SA')\n",
    "\n",
    "true_gs_energy = smallest_eigenvalue[0]\n",
    "true_gs_vec = smallest_eigenvector[:, 0]\n",
    "\n",
    "# Compute the largest eigenvalue\n",
    "largest_eigenvalue = eigs(HA_matrix + B * HB_matrix, k=1, which='LR', return_eigenvectors=False)\n",
    "\n",
    "E_max = largest_eigenvalue[0].real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "335e9987-c119-465e-8c03-19ae4e9e6bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true ground state energy is -7.887943169537985\n"
     ]
    }
   ],
   "source": [
    "print('true ground state energy is', true_gs_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecacef1f-cf97-46d1-a321-bc30a7c23c16",
   "metadata": {
    "id": "ecacef1f-cf97-46d1-a321-bc30a7c23c16",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get  ground state with numerically infinite large B field\n",
    "# Compute the smallest eigenvalue and eigenvector\n",
    "smallest_eigenvalue, smallest_eigenvector = eigsh( HB_matrix, k=1, which='SA')\n",
    "temp_vec = smallest_eigenvector[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "586f0265-b7e7-4eab-af31-e68b1f1e26f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to gpu\n",
    "true_gs_vec = torch.tensor(true_gs_vec.astype(np.complex128)).to(device=device)\n",
    "temp_vec = torch.tensor(temp_vec.astype(np.complex128)).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a9cbca-d47e-4c50-b045-dfc00747188b",
   "metadata": {
    "id": "e0a9cbca-d47e-4c50-b045-dfc00747188b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fidelity before optim is tensor(0.0014, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# get fidelity for t= 0s\n",
    "fidelity_t_0 = get_fidelity_torch(true_gs_vec,temp_vec)\n",
    "print('fidelity before optim is', fidelity_t_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e74f53-96c8-4dff-b0a3-47725ac22589",
   "metadata": {
    "id": "b2e74f53-96c8-4dff-b0a3-47725ac22589",
    "tags": []
   },
   "outputs": [],
   "source": [
    "HA_matrix = torch.tensor(HA_matrix, dtype=torch.complex128).to(device=device)\n",
    "HB_matrix = torch.tensor(HB_matrix, dtype=torch.complex128).to(device=device)\n",
    "target_H = HA_matrix + B * HB_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "749f89a9-2441-4d1e-a916-f0cf2830cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_evolve(x_A, x_B):\n",
    "    global fidelity\n",
    "    p = temp_vec.clone()\n",
    "    # Loop through each time step\n",
    "    for i in range(len(x_A)):\n",
    "        H_matrix = x_A[i] * HA_matrix + x_B[i] * HB_matrix\n",
    "        exp_imgH_matrix = torch.matrix_exp(1j * H_matrix)\n",
    "        new_p = torch.mv(exp_imgH_matrix, p)\n",
    "        p = new_p\n",
    "\n",
    "        # Get energy\n",
    "        energy = get_energy_torch(target_H, p)\n",
    "\n",
    "    # Compute fidelity\n",
    "    fidelity = get_fidelity_torch(true_gs_vec, p)\n",
    "    print('fidelity is',fidelity)    \n",
    "    return energy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45a53bc1-7a46-4be4-aca1-2d14b2de0769",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_m(a, b, max_ratio):\n",
    "    \n",
    "    a = np.abs(a)\n",
    "    b =np.abs(b)\n",
    "    \n",
    "    # Start with an initial value for m\n",
    "    m = 1\n",
    "    \n",
    "    # Define a function to calculate the ratio (a/m + b/m) / (a+b)\n",
    "    def ratio_function_1(m):\n",
    "        return ( (a*a*b)/(24*m*m) ) / (a + b)\n",
    "    \n",
    "    def ratio_function_2(m):\n",
    "        return ( (a*b*b)/(12*m*m) ) / (a + b)\n",
    "\n",
    "    for m in range(1,200):\n",
    "        \n",
    "        if ratio_function_2(m)<max_ratio and ratio_function_1(m)<max_ratio:\n",
    "            #print(ratio_function_1(m),ratio_function_2(m))\n",
    "            best_m = m\n",
    "            break\n",
    "    return best_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a63a40e-a862-452d-a941-e5707cece8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the array\n",
    "length = len(x)\n",
    "# Split the array into two halves\n",
    "x_A = x[:length//2]\n",
    "x_B =x[:length//2] * x[length//2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fb5b18-5e86-45f9-8e25-f7ad17e083e7",
   "metadata": {},
   "source": [
    "The following cell computes the energy and fidelity using the input x in MTE form, serving as a check to ensure the input is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7f74399-a4df-4f5b-ae4e-67d33886afe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fidelity is tensor(0.9277, device='cuda:0', dtype=torch.float64)\n",
      "energy is -7.743098451542654\n"
     ]
    }
   ],
   "source": [
    "print('energy is',lambda_evolve(x_A,x_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6dca0b-0c62-4c6d-901e-91e8aa909107",
   "metadata": {},
   "source": [
    "Here, we input a m value , details are in https://doi.org/10.48550/arXiv.2408.03251 supplemental file\n",
    "- N=12 \n",
    "- 0.007 for 31 layers\n",
    "- 0.004 for 41 layers\n",
    "- 0.0024 for 51 layers\n",
    "- 0.0016 for 61 layers\n",
    "- 0.0011 for 71 layers\n",
    "- 0.00085 for 81\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82a7ac1d-2fa5-4bdb-8c9c-f2c30d7c5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get p_list from ratio\n",
    "p_list =[]\n",
    "for i in range(len(x_A)):\n",
    "    p = find_m(x_A[i], x_B[i], 0.007)     \n",
    "    p_list.append(p)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f26d7c5-98a4-4f45-ac97-6545a9710660",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_expand_amps(gamma,beta,layers):\n",
    "    \n",
    "    if layers ==1:\n",
    "        gamma_series = np.array([gamma/2,gamma/2])\n",
    "        beta_series = np.array([beta])\n",
    "        \n",
    "    else:\n",
    "        gamma_series = np.ones(layers-1)*(gamma/layers)\n",
    "        # Add an element to the first index\n",
    "        gamma_series = np.insert(gamma_series,0,(gamma/(2*layers)))\n",
    "        gamma_series = np.insert(gamma_series,len(gamma_series),(gamma/(2*layers)))\n",
    "        \n",
    "        beta_series = np.ones(layers)*(beta/layers) # plus one for the first one \n",
    "    \n",
    "    return gamma_series,beta_series\n",
    "    \n",
    "\n",
    "from itertools import chain\n",
    "# get qaoa like input\n",
    "new_x_A_list =[]\n",
    "new_x_B_list =[]\n",
    "for i in range(len(x_A)):\n",
    "    gamma = x_A[i]\n",
    "    beta = x_B[i]\n",
    "    index_of_power = p_list[i]\n",
    "    #print(index_of_power)\n",
    "    new_x_A,new_x_B = get_expand_amps(gamma,beta,index_of_power)\n",
    "    \n",
    "    # append result\n",
    "    new_x_A_list.append(new_x_A)\n",
    "    new_x_B_list.append(new_x_B)\n",
    "\n",
    "#new_x_A_list = list(chain.from_iterable(new_x_A_list))\n",
    "new_x_B_list = list(chain.from_iterable(new_x_B_list))\n",
    "\n",
    "\n",
    "flattened_new_x_A_list = []\n",
    "\n",
    "for i, sublist in enumerate(new_x_A_list):\n",
    "    if i > 0:\n",
    "        flattened_new_x_A_list[-1] = flattened_new_x_A_list[-1] + sublist[0]\n",
    "        flattened_new_x_A_list.extend(sublist[1:])\n",
    "    else:\n",
    "        flattened_new_x_A_list.extend(sublist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c6201c8-e229-4f1b-a1ba-59b6b8a59895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "# get qaoa like input\n",
    "new_x_A_list =[]\n",
    "new_x_B_list =[]\n",
    "for i in range(len(x_A)):\n",
    "    gamma = x_A[i]\n",
    "    beta = x_B[i]\n",
    "    index_of_power = p_list[i]\n",
    "    #print(i)\n",
    "    #print(index_of_power)\n",
    "    new_x_A,new_x_B = get_expand_amps(gamma,beta,index_of_power)\n",
    "    \n",
    "    # append result\n",
    "    new_x_A_list.append(new_x_A)\n",
    "    new_x_B_list.append(new_x_B)\n",
    "\n",
    "#new_x_A_list = list(chain.from_iterable(new_x_A_list))\n",
    "new_x_B_list = list(chain.from_iterable(new_x_B_list))\n",
    "\n",
    "\n",
    "flattened_new_x_A_list = []\n",
    "\n",
    "for i, sublist in enumerate(new_x_A_list):\n",
    "    if i > 0:\n",
    "        flattened_new_x_A_list[-1] = flattened_new_x_A_list[-1] + sublist[0]\n",
    "        flattened_new_x_A_list.extend(sublist[1:])\n",
    "    else:\n",
    "        flattened_new_x_A_list.extend(sublist)\n",
    "\n",
    "x_1 = np.concatenate((flattened_new_x_A_list,new_x_B_list))\n",
    "x_1 = torch.tensor(x_1, dtype=torch.float64, device=device, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77aa8543-11e0-4744-9e5b-f19ad320fbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of QAOA layers is 31\n"
     ]
    }
   ],
   "source": [
    "print('number of QAOA layers is',len(flattened_new_x_A_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10ec44e6-f600-4225-baa1-de792f5a5913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lambda_evolve_qaoa_for_optim(x):\n",
    "\n",
    "    location = len(x) // 2 + 1\n",
    "\n",
    "    x_A = x[:location]\n",
    "    x_B = x[location:]    \n",
    "    #global fidelity\n",
    "\n",
    "    p = temp_vec.clone()\n",
    "\n",
    "    number_of_layers = len(x_B)\n",
    "    for i in range(number_of_layers):\n",
    "        exp_imgHA_matrix = torch.matrix_exp(1j * HA_matrix * x_A[i])\n",
    "        exp_imgHB_matrix = torch.matrix_exp(1j * HB_matrix * x_B[i])\n",
    "\n",
    "        H_eff = torch.matmul(exp_imgHB_matrix, exp_imgHA_matrix)\n",
    "        new_p = torch.mv(H_eff, p)\n",
    "        p = new_p\n",
    "        \n",
    "    # Apply the extra x_A\n",
    "    exp_imgHA_matrix = torch.matrix_exp(1j * HA_matrix * x_A[-1])\n",
    "    new_p = torch.mv(exp_imgHA_matrix, p)\n",
    "    p = new_p\n",
    "    energy = get_energy_torch(target_H, p)\n",
    "    \n",
    "    # fidelity = get_fidelity_torch(true_gs_vec, p)\n",
    "    # fidelity = fidelity.item()\n",
    "    # print('fidelity is {:.10f}'.format(fidelity))\n",
    "    # print(torch.norm(p).item())\n",
    "    \n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c284929d-e554-4e54-8627-e4f2d335fc95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_fidelity_list(x):\n",
    "    global fidelity_list\n",
    "    fidelity_list = []\n",
    "    if len(x)%2==1:\n",
    "        location = len(x) // 2 + 1\n",
    "    else:\n",
    "        location = len(x)//2\n",
    "    x_A = x[:location]\n",
    "    x_B = x[location:]    \n",
    "    global fidelity\n",
    "\n",
    "    p = temp_vec.clone().to(torch.complex128)  # Create a copy of temp_vec\n",
    "\n",
    "    number_of_layers = len(x_B)\n",
    "    if len(x_A) == len(x_B):\n",
    "        # print('y')\n",
    "        for i in range(number_of_layers):\n",
    "            exp_imgHA_matrix = torch.matrix_exp(1j * HA_matrix * x_A[i])\n",
    "            exp_imgHB_matrix = torch.matrix_exp(1j * HB_matrix * x_B[i])\n",
    "\n",
    "            H_eff = torch.matmul(exp_imgHB_matrix, exp_imgHA_matrix)\n",
    "            new_p = torch.matmul(H_eff, p)\n",
    "            p = new_p\n",
    "            fidelity = get_fidelity_torch(true_gs_vec, p)\n",
    "            fidelity = fidelity.item()\n",
    "            fidelity_list.append(fidelity) \n",
    "    else:\n",
    "        for i in range(number_of_layers):\n",
    "            #print('yy')\n",
    "            exp_imgHA_matrix = torch.matrix_exp(1j * HA_matrix * x_A[i])\n",
    "            exp_imgHB_matrix = torch.matrix_exp(1j * HB_matrix * x_B[i])\n",
    "\n",
    "            H_eff = torch.matmul(exp_imgHB_matrix, exp_imgHA_matrix)\n",
    "            new_p = torch.matmul(H_eff, p)\n",
    "            p = new_p\n",
    "            fidelity = get_fidelity_torch(true_gs_vec, p)\n",
    "            fidelity = fidelity.item()\n",
    "            fidelity_list.append(fidelity) \n",
    "            \n",
    "        # Apply the extra x_A\n",
    "        exp_imgHA_matrix = torch.matrix_exp(1j * HA_matrix * x_A[-1])\n",
    "        new_p = torch.matmul(exp_imgHA_matrix, p)\n",
    "        p = new_p\n",
    "        fidelity = get_fidelity_torch(true_gs_vec, p)\n",
    "        fidelity = fidelity.item()\n",
    "        fidelity_list.append(fidelity)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f3a97ab-4d0b-43da-8388-26ed169cddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lambda_evolve(lr, gradient_threshold, filename, checkpoint_filename):\n",
    "    # Initialize x if checkpoint does not exist\n",
    "    if os.path.isfile(checkpoint_filename):\n",
    "        checkpoint = torch.load(checkpoint_filename)\n",
    "        x = checkpoint['x']\n",
    "        optimizer = optim.Adam([x], lr=lr)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "    else:\n",
    "        x = np.concatenate((flattened_new_x_A_list,new_x_B_list))\n",
    "        x = torch.tensor(x, dtype=torch.float64, device=device, requires_grad=True)\n",
    "        # start the code\n",
    "        optimizer = optim.Adam([x], lr=lr)\n",
    "        epoch = 0\n",
    "\n",
    "    with open(filename, 'a') as f:  # Use 'a' to append to the log file if it exists\n",
    "        while True:\n",
    "            optimizer.zero_grad()\n",
    "            energy = lambda_evolve_qaoa_for_optim(x)\n",
    "            energy.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            gradient_norm = x.grad.norm().item()\n",
    "            if (epoch + 1) % 1 == 0:\n",
    "                result_str = f\"Epoch {epoch + 1}, Energy: {energy:.6f}, Energy ratio: {energy/true_gs_energy:.6f}, Gradient Norm: {gradient_norm:.6f}\\n\"\n",
    "                f.write(result_str)\n",
    "                print(result_str, end='')\n",
    "                \n",
    "                # Append latest x values to the end of the file\n",
    "                x_values = ','.join([str(val.item()) for val in x.detach().cpu().numpy()])\n",
    "                f.write(f\"Latest x values at epoch {epoch + 1}: {x_values}\\n\")\n",
    "                #print(x_values)\n",
    "                # Save checkpoint\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'x': x,\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, checkpoint_filename)\n",
    "\n",
    "            if gradient_norm < gradient_threshold:\n",
    "                break\n",
    "\n",
    "            epoch += 1\n",
    "            f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2864509-90ac-4f69-9716-f89e7bec2173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = f'QAOA_training_log_N={N}_B={B}_layers_{np.sum(p_list)}.txt'\n",
    "checkpoint_filename = f'QAOA_checkpoint_log_N={N}_B={B}_layers_{np.sum(p_list)}.pt'\n",
    "# Execute the following line to run the optimization.\n",
    "###########################################\n",
    "\n",
    "train_lambda_evolve(0.01, 0.0001, filename, checkpoint_filename) # learning rate is 0.01 and gradient_threshold is 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60012501-3d4e-4f59-bc2f-947a2df0cd1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example usage based on previously optimized data.\n",
    "best_30= np.array([0.09883560217862536,0.29694661452567783,-0.04223160455803097,0.34181833185331073,0.445708802140215,0.06395875308781014,-0.11792400368569012,0.10450382791716804,0.45155063856821553,0.36773186562921584,0.3863144467491393,0.39546759474137805,0.404117194948392,0.3967876132794703,0.40748532879952903,0.4099682623145645,0.40656032453149993,0.4125831926125769,0.3926871711459888,0.4130993265682991,0.4203272478053987,0.422596280764216,0.4229697451117508,0.43198254299121674,0.4497398463801568,0.45602406596982586,0.4876138744248867,0.534394230545182,0.5543904072606549,0.6271244896223498,1.5167029563561208e-05,0.4906107243574948,1.1078658145481528,0.9035715524291998,0.24417628356738635,0.4413182695174657,0.7183517990437245,0.43254690242630117,0.4299498753313533,0.216668514283277,0.21673022670131928,0.21574089603285987,0.20957406675069212,0.20081762127126224,0.19750743053319525,0.19584105814594038,0.190340461508735,0.18713658074980472,0.18085387666004657,0.16948479532136507,0.17731147459550622,0.17214489959363782,0.17318536422139827,0.16991322232129275,0.17008332423645686,0.1652976299524704,0.15444635288438988,0.15705058885756187,0.1537392636682203,0.13881566146195073,0.08520288908426696])\n",
    "best_30 = torch.tensor(best_30, dtype=torch.float64, device=device, requires_grad=False)\n",
    "best_40= np.array([0.08881331901466091,0.20254001129362792,0.24688487477037965,0.28302925664456213,0.2848820234049403,0.2660245719451472,0.374766081173048,0.06431200038651136,-0.0608531065744281,0.08130627174407143,0.4156532134983728,0.34745130689167936,0.34631921805344956,0.3375800372112298,0.3242013207429833,0.3372144424188058,0.3588928802164133,0.3705324112499944,0.3810622128238857,0.3885167426488866,0.39844906724448137,0.4019157548540339,0.41218599498050507,0.41614163518812536,0.4165136150239514,0.4089295159127287,0.401108472087148,0.39835036734262336,0.4074636908403127,0.42188869857300826,0.4129301982664925,0.41177241637976386,0.40729633217424543,0.43054826354083,0.4508635131685727,0.46410595849413133,0.5063852033835946,0.5494401769194854,0.567086434793776,0.6247390181548891,6.746421110907407e-05,0.5140990470938749,0.3503380067226817,1.8572707132079727,0.25001432998937884,0.21136932729853308,0.18492777709502156,0.35586506020101705,0.6635980532307426,0.5757455634514476,0.3455680802619926,0.20094258852901678,0.19624133326039417,0.18638050345769977,0.17414677750097998,0.1669682636408392,0.17628003493106556,0.18054087003357353,0.18390548713408136,0.18447899397739304,0.18591629387563607,0.18550485808028688,0.1830903180342377,0.1834495917302014,0.18320293634987184,0.18253822676843245,0.17838874003137642,0.17459778516576274,0.16814250620110413,0.17022111148954094,0.16564478275879155,0.1638668057250036,0.1607868427183128,0.16235156765931685,0.1645419676426412,0.15781543456698666,0.15243991951605224,0.1562192267972927,0.15256539042834527,0.13236262197763693,0.07430557266090056])\n",
    "best_40 = torch.tensor(best_40, dtype=torch.float64, device=device, requires_grad=False)\n",
    "best_50= np.array([0.08202858153292118,0.27033773130163047,0.04726475971313934,-0.10368191723038658,0.056835232625533506,0.34516291772960866,0.2641919653947468,0.2824210789231795,0.38811092399271063,0.07858827171035965,-0.061015802739330965,0.0793511055124828,0.4076720877732578,0.32732681602194985,0.32721665776209363,0.32290728426629034,0.3073305102928346,0.30473011349578427,0.312375739167832,0.31401451215619613,0.33022635080157503,0.347303661742102,0.3514754725888425,0.3560128895907037,0.3632019631063949,0.3698581091869817,0.37183544827030757,0.37317146582776906,0.3773937241609838,0.37830693567774437,0.37448166019869406,0.376926014016424,0.37240270124700636,0.362087483263841,0.36517567305338183,0.3785328261009834,0.37756628702474676,0.3757191721459734,0.38491419965082246,0.3927663435591142,0.39460924268261416,0.38896012391910983,0.4054603986158366,0.42407131260906056,0.436475078950618,0.49900568625481273,0.571196121891741,0.6104590213056507,0.6042606645196058,0.6071903106756192,0.00012414087511123534,0.5346562075268407,0.5049671489347731,0.6632433400547064,0.5272045023043983,0.5012373567358367,0.25104700584115924,0.2268166241632921,0.22039413393726037,0.3170830684440872,0.7348626390058447,0.5442898244640234,0.3660123640065208,0.19884133562152703,0.19123932085919504,0.1870098761535026,0.1741588917793626,0.16201305733673352,0.16094172304521376,0.16075212974863734,0.16061918314496992,0.16829226667179614,0.17000692323561195,0.16916506569238415,0.17024358506552928,0.1705698595797983,0.1695282682019988,0.1677201624095296,0.16840418398206647,0.1685549202662053,0.1662892736469787,0.16330504732605775,0.16066980231647146,0.1551411017064267,0.15076082846017622,0.15449528522054126,0.15702750379981856,0.15170761510966413,0.1497256630797447,0.14816515959326435,0.14389230072870318,0.14080923901622086,0.135972523004814,0.1412283949687429,0.13290922811976083,0.13157248893698967,0.1364824384971456,0.1303150189703873,0.11755555152255949,0.09773266659415607,0.05135425464600847])\n",
    "best_50 = torch.tensor(best_50, dtype=torch.float64, device=device, requires_grad=False)\n",
    "best_60= np.array([ 0.06324719379437627,0.1473716594160256,0.25102311196385574,-0.03275432400399373,-0.02859591983106859,0.31300741232086826,0.24477415476125466,0.22997098076543457,0.2277591667251185,0.3396279292723425,0.06353274826292464,-0.013309454384126791,-0.04631006697879746,0.10474508092410711,0.33622537339215675,0.2723483914817253,0.27451333911286024,0.28746114694459485,0.29522306852454633,0.28958834849512155,0.27548785116354385,0.2700226978553042,0.299248647345696,0.32173063644254224,0.3312646203616534,0.33706537836173156,0.3410480872401923,0.320518293979827,0.2983267118589641,0.29623015581253614,0.3005504287830846,0.3242337630964402,0.3534339685065611,0.36003051731913355,0.358573636148054,0.3690533954940621,0.3773851977218561,0.37628881975349765,0.3788366553287864,0.3809124443172497,0.36664913893740175,0.36899989712282655,0.3927333447853013,0.4022328551129756,0.39008668907342464,0.38680842497387774,0.39325087583714824,0.39028233735061485,0.3914544524015571,0.40186616425934546,0.4151329042561052,0.4344628143428997,0.48761727705451324,0.5225635483260939,0.5327506540171775,0.5313307717532096,0.5481747856582048,0.5743001892148237,0.5694139410773734,0.5709183684838275,0.0033531825490181522,0.5328225872065516,0.3726208383575648,0.5330702567353865,0.9729347768144168,0.4487922983562509,0.2586179057252713,0.2139561266700648,0.17932570587158997,0.1734832118616349,0.36182712444700976,0.3159727642425698,0.5345613851220813,0.4159635756743863,0.2991275851552877,0.17102992999372835,0.16388107373066807,0.16512437156151416,0.16769566056573848,0.1639162819360573,0.1522120586386143,0.14128682884551216,0.14535571612642575,0.15831851511123654,0.1631581816643168,0.16543105699506355,0.16632730410738508,0.16164724628251803,0.1452741856467702,0.1371256049195222,0.13717814221417687,0.13998794058601924,0.15458776413996753,0.1622427139123582,0.16094161437218887,0.16120041405578878,0.16484143584347485,0.1636647967872986,0.16226425793204335,0.16304273628152335,0.15851941639846115,0.14998913448620455,0.15451251504402427,0.15862480771468132,0.15497302992012754,0.14820062283113367,0.1466077491793567,0.14304871466919428,0.13373663018801232,0.12802565921149206,0.12475311976138155,0.12199427316176999,0.12798300110236469,0.13429903991493575,0.13048073033163843,0.12264157427453835,0.11565392950110827,0.1138690155738625,0.10753542788266177,0.09173414300514689,0.048231576391915075])\n",
    "best_60 = torch.tensor(best_60, dtype=torch.float64, device=device, requires_grad=False)\n",
    "best_70= np.array([0.05013361299216526,0.11713905899313692,0.15493695714930078,0.18704079692964928,0.2086986281535457,0.2241520882218094,0.2315867340862514,0.23704426589590494,0.2510306132558461,0.26261350190598987,0.26291254551124166,0.2449045368997676,0.20181387411691376,0.04109938502361471,-0.010921756851566683,0.011115324503567777,0.11361259461322747,0.2568053072635486,0.2678802651968086,0.28043365403580084,0.282759715116457,0.2792827789158674,0.2676223075474714,0.27121663114423655,0.28108655551348016,0.2779633623407621,0.2685850836378745,0.2717644631529878,0.28962570276266286,0.29950201645268604,0.29649354176830045,0.292907213864896,0.29852088603587945,0.307418523547124,0.30900500827322464,0.3067995468967261,0.2967923993406924,0.2825291647027424,0.29560557952741273,0.3172541670239796,0.32289414783763437,0.31080985934017313,0.29119864864527806,0.2949904090260997,0.31158732827354363,0.3323287362724592,0.34991163805477093,0.3554512327000839,0.36154337770355083,0.36997664478871306,0.3745331686654994,0.3785821830147145,0.38622966565721034,0.38709489340127995,0.38813114352832484,0.39475020141305145,0.3991030401909274,0.40777683161047346,0.4158517686371176,0.41387300126254994,0.40582932859685866,0.40842690273263493,0.40685822221594975,0.40961348959646643,0.4150430169566799,0.42408285067126633,0.49226858623908964,0.5532016252011881,0.5666924877409893,0.5147264737079338,0.09214233652676866,0.5460472810716175,0.3809261017837478,0.3147289552738696,0.2691564805038066,0.2413992551531472,0.21844214141814963,0.1983225971396291,0.18957420571415856,0.18733240425156497,0.18072272294209954,0.16740899573574583,0.14000915730631777,0.2719474328072933,0.5105206183252895,0.5420467261006625,0.3221482933887958,0.15555561424812453,0.15130966983475924,0.15700674117692595,0.1569443725149228,0.15342481108915237,0.14549576750354834,0.1389512155127716,0.14253039193097283,0.14231253005986724,0.13620064751913707,0.13155731984753277,0.13660383330376138,0.14259767571174048,0.14223229777279142,0.1383113311151506,0.13737510150566187,0.14061349793996164,0.1418370372761194,0.1399839986871965,0.13655339568118408,0.12829526381159378,0.12591074837348476,0.13523800117065657,0.14068912317292237,0.1385568312241086,0.12906140992984697,0.12352580612272705,0.12774802616709433,0.1336012248298797,0.14053321051240666,0.14324148572489506,0.14288524125547256,0.14433419913647663,0.14426875712597623,0.14180120178171263,0.13986209898214066,0.13658656788517612,0.13054794053523006,0.12672308202677976,0.12308307894542429,0.11903773946259061,0.1173562961086389,0.11373851252161826,0.10840941437948154,0.10405513843053778,0.10100529845518377,0.09564052369014064,0.0920048087920932,0.08558116430354869,0.08544183545850055,0.08973231004609589,0.08508157111921852,0.0717415625442238,0.04131235746511464])\n",
    "best_70 = torch.tensor(best_70, dtype=torch.float64, device=device, requires_grad=False)\n",
    "best_80= np.array([0.030574082179259877,0.05084334633462071,0.09669739277208426,0.1345342515743292,0.15630571815915417,0.14921695689732206,0.12627133482694622,0.16650592937283168,0.17779588708990926,0.12529076786496607,0.1626375935924034,0.2070229212281155,0.1564364606393484,0.1607388033763727,0.07737519082209679,-0.003228520025742783,-0.007129563460275362,0.07627722047518848,0.1567939606562988,0.20303692941977936,0.2529986140301044,0.25238856229593587,0.17671639502200176,0.17059531322206672,0.2489947436130967,0.2682867124468809,0.2778118460749751,0.28305417673453065,0.2846943589079045,0.28349193843310483,0.2807287474549748,0.2783860220669825,0.2795291429044335,0.2798544342776568,0.27748664196720674,0.2794062375909371,0.2854797701474966,0.28710578197934467,0.28413769683772805,0.28179156614413314,0.28707735452502864,0.2988145855460415,0.30717780879951784,0.3077577187481952,0.3069555639903366,0.30607067755891953,0.30186799306782536,0.30032988033368874,0.30230719515668053,0.2971937366080384,0.29154868968833164,0.30430922637297514,0.3191180322555967,0.3195764216992493,0.3183304258019918,0.3169878838469653,0.31294141965813954,0.3165448393867777,0.3195386826069848,0.3274444047160869,0.34522841145892985,0.36270402164986765,0.37799047535542357,0.386445118910997,0.3884215339201508,0.39050534564990397,0.39591473734043564,0.4006579277143043,0.40604501149746897,0.4082101386654194,0.4039046842123338,0.40298277419593814,0.4049031106392406,0.40928556851350945,0.42071816372648757,0.43021525279403244,0.46708637850964335,0.5117661509526434,0.5234794874676824,0.4444656412648462,0.06799800348820806,0.4334536796946855,0.32937284275483786,0.33484391521837287,0.29402662972250215,0.24235465306686133,0.17255891653535346,0.16529864981768452,0.18635285728506984,0.1457851728881418,0.10999535055673985,0.16092354378930734,0.15542568355041952,0.08585547361272676,0.2263975058691485,0.3446115849620437,0.6542489110273112,0.36665545400985367,0.2185287533643568,0.10209474268547145,0.15527833389054088,0.16103871958596122,0.13972034224052726,0.08092955509336158,0.13086060938716204,0.1487043748646528,0.15254744117384467,0.15348464329316808,0.15216149155328498,0.14935948362188875,0.1457777991056799,0.14185766870893105,0.1396392359016095,0.13860933083200488,0.1360435553438115,0.1336367352124105,0.13483671818364865,0.13567482132669526,0.133686821789748,0.13117633707461923,0.13018870489913117,0.13348053016489578,0.13759356465928355,0.1382466730372829,0.13670428531623247,0.13555077039386132,0.1333259755647205,0.13060659618025564,0.130059224556431,0.12878625003453592,0.12382113480018392,0.12368565590897794,0.1298287149843957,0.13132471258455702,0.12894894480162025,0.12716179615858833,0.12374508222094817,0.12097862814848444,0.1202634951928484,0.1186241701668569,0.12072710670225802,0.12362654433657444,0.12529243515958857,0.1246270733912611,0.12112677647583363,0.11679837775451114,0.11354716676163806,0.1109955604745495,0.10862021372192879,0.10617829270941763,0.10188074271814684,0.09591574768147303,0.09104027872921851,0.08530698198302093,0.08110165293474161,0.0760664838339432,0.07214740506045358,0.07211557019939345,0.06931856444022175,0.059231561840442364,0.03105179779867607])\n",
    "best_80 = torch.tensor(best_80, dtype=torch.float64, device=device, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f9751-a1c5-4c7c-a81f-eebd0dc94f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result from previously optimized data.\n",
    "lambda_evolve_qaoa_for_optim(best_80)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
